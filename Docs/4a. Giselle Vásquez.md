## Agentes para juegos

- [Boulder Dash](https://www.boulder-dash.com/boulder-dash-online-game/)

### TODO

Preparar explicación/presentación **actor-critic** código.
  -  Explicar paso a paso el algoritmo
  - Dónde se recolectan las observaciones
  - ¿Qué se almacena en el buffer?
  - ¿Cómo se calcula el advantage_buffer?
  - ¿En qué momento se entrena el actor y el crítico? ¿Al final de las épocas?
  - ¿Cuáles son los inputs?
  - ¿Cómo se calcula el loss en ambos modelos?
  - Otros detalles importantes


### Idea: Simulador automático para entrenar agentes

[track de trayectoria](https://github.com/deepankarkotnala/Object-trajectory-tracking-OpenCV)

- Recompensa es **sparse**. Augmentation of trajectories.

![GeneralFramework](https://i.imgur.com/byclaVc.png)

![GeneralFramework](https://i.imgur.com/YVsLgZf.png)

![TrainedSimulator](https://i.imgur.com/LLd7NTS.png)

**Versión 2.0**

![simulador2.0](https://i.imgur.com/N9IUB0m.png)


**Versión 3.0**

**Simulator**: Red que aprende a simular observaciones a partir de 
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjI4MzA4NjQxLDEyODQ3MjI4NjYsLTgzMT
U3NDEyMiwtNDQ4Njg4MjkwLDIwNzA2Njg1MTEsLTcwNTQ2Mzgz
LDE2NjYxNDk0ODldfQ==
-->