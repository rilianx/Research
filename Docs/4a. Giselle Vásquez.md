## Agentes para juegos

- [Boulder Dash](https://www.boulder-dash.com/boulder-dash-online-game/)

### TODO

Preparar explicación/presentación **actor-critic** código.
  -  Explicar paso a paso el algoritmo
  - Dónde se recolectan las observaciones
  - ¿Qué se almacena en el buffer?
  - ¿Cómo se calcula el advantage_buffer?
  - ¿En qué momento se entrena el actor y el crítico? ¿Al final de las épocas?
  - ¿Cuáles son los inputs?
  - ¿Cómo se calcula el loss en ambos modelos?
  - Otros detalles importantes


### Idea: Simulador automático para entrenar agentes

[track de trayectoria](https://github.com/deepankarkotnala/Object-trajectory-tracking-OpenCV)

- Recompensa es **sparse**. Augmentation of trajectories.

![GeneralFramework](https://i.imgur.com/byclaVc.png)

![GeneralFramework](https://i.imgur.com/YVsLgZf.png)

![TrainedSimulator](https://i.imgur.com/LLd7NTS.png)

**Versión 2.0**

![simulador2.0](https://i.imgur.com/N9IUB0m.png)

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTI4NDcyMjg2NiwtODMxNTc0MTIyLC00ND
g2ODgyOTAsMjA3MDY2ODUxMSwtNzA1NDYzODMsMTY2NjE0OTQ4
OV19
-->