## P=simplex

### TODO

- Contractar usando dual [carpeta](https://drive.google.com/drive/folders/1EBatxitD8enREBngiIVP3IQxY7Gimv8J)
- Actualizar P (si reduce >60%), actualizar A siempre
- Comparar primal con dual. **solucionado**.





**Primal**
![image](https://i.imgur.com/WEwUunD.png)

![image](https://i.imgur.com/WdspZ3Z.png)

**Dual**
![image](https://i.imgur.com/4pQ7ZSj.png)

### Plan

1. Hacer experimentos que demuestren que usar CtcDual sería prometedor
2. Adaptar paper para nuevos experimentos

---
### Algoritmo 

**Estrategia general**:
1. Se busca en la lista (desde el final) la caja que contenga la caja actual (P.Ax=b).
2. Si la diferencia de tamaños es menor a un threshold:
   a. Se usa


3. Se decide si se continua con P (comparando el tamaño de la caja). Si no cumple se lineariza y se recalcula P.
4. Si se decida linearizar, se actualiza A y se recalcula P, PA y PB. 
5. GS normal (smart propagation).


**GS normal + smart propagation**
- Guardar sumas dentro del método
- Mejora cada bound usando la sumatoria.
- **Agregar variables contractadas a una cola y repetir proceso**
- Guardar últimas sumas asociadas a las cajas.

![image](https://i.imgur.com/tFInT4b.png)

**Actualización de matrices**

- Cada linearización debería estar asociada a una fila de la matriz A (mapa: id->fila).
- Cada vez que ctc_dualP necesite linearizar, llama al linearizador, y actualiza las filas correspondientes de la matriz A. Las filas *factibles* (que no son retornadas por el linearizador), se eliminan de A.

**¿Por qué extender matrices? Ejemplo**
Variables de holgura se contractan

$x+y \leq 0$, $x+y \geq 0$,

$\begin{pmatrix}  
1 & 1 & -1 & 0\\  
1 & 1 & 0 & -1\\  
\end{pmatrix}.
\begin{pmatrix} x\\  y\\  b_1\\  b_2\\  \end{pmatrix}=0$

Precondicionando a mano:

$\begin{pmatrix}  
1 & 1 & -1 & 0\\  
0 & 0 & 1 & -1\\  
\end{pmatrix}.
\begin{pmatrix} x\\  y\\  b_1\\  b_2\\  \end{pmatrix}=0$ 
$\Rightarrow b_1=b_2=0; x+y=0$


**Otros**
- ¿Cómo actualizar los lambda?

---

**Paper P.Simplex**
[Paper](https://www.overleaf.com/project/5f0c82e6b4fb520001ade779)

- Modificar parte de experimentación en abstract (al final)
- Cambiar título :ok:
- Modificar intro :ok:
- ==Identificar instancias en las cuales Simplex es muy costoso (experimentos preliminares)==
- ==Comparar precondicionadores en instancias de COCONUT==
- PlanB: Crear instancias ad-hoc (lineal+nolineal)

## AbsTaylor

- Abstaylor random no funciona bien
- IterativeTaylor gain 1.10 en tiempo y 1.20 en cajas


## [Removing points](https://docs.google.com/file/d/14GLEQcDA-WfSRv5xqI3-dllyPWhiue2f/edit)

When solving multi-objetive problems with global optimization solvers, generally a set  of non dominated points (upper envelope) is maintained and updated in each iteration. During the search, the set is mainly used for discarding and filtering dominated regions of the search space.

In order to keep a reduced size of the set of non dominated points, the idea of this work is to propose a mechanism for removing points such that the quality of the set  *does not get too much worse*. 

### Plan:

- Solucionar problema de IbexMOP. Pareciera que se están eliminando cajas factibles
- Implementar reducción de puntos a partir de [código de kevin](https://github.com/rilianx/Research/tree/main/ibexmop_rp)
- Probar en benchmarks conocidos 


## Updating preconditioners

### Plan:

1.  Calcular (para saber cuánto se puede ganar):
     - Relación temporal entre linearización y resolución de simplex
     - Relación temporal entre PolytopeHull y análisis del nodo
2. Implementar contractor CtcLinearRelaxPrecond que genere precondicionadores-fila (para cada variable) usando las soluciones duales de los 2n simplex.
3. Optimizar contracción basada en cambios de bounds de variables de entrada. 
4. **Identificar precondicionadores-fila que se deben actualizar y subsistema que se debe considerar.**

**Observación:**
Para variables que son monótonas crecientes en función objetivo e independientes entre sí (sin links en el grafo de restricciones). El lb de las variables se puede obtener minimizando la suma de estas. El ub de las variables se limita por la restricción f(x)<UB

## IbexMop + spline
 
 A bi-objective optimization problem is defined as a function of two objectives to be minimized, subject to a set of restrictions, composed of arithmetic functions, on a set of unkown variables comprised in a bounded domain to a n-dimentional box x. These problems have as objective search a representation of feasible and non dominated solution set. Interpolation is a process used to predict a new point from other points already known. As regard to the functions, by means of interpolation it is possible get to approximation of the resultant curve. 

In this paper, we propose a new method for finding an approximation of the non dominated set. It combines an exact method for searching efficient solutions and an interpolation method for finding promising regions in the search space. Compared to exact bi-objective method, the approach *should be* much faster reaching a quite comparable set of solutions.

**Plan:**

- Apoyar a Giselle con la confección del artículo
- Revisar el algoritmo (implementación en python y escritura en artículo) para que quede tiqui taca
- Experimentos propuestos: comparar algoritmo con IbexMop en problemas con 2 objetivos 
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTc5NDc2MTQwOSwtODQ5OTI4MTY0LDQ4MT
U3NTgyNiwtMjA0OTg0MDkzMCw5Njc2NzcwMzUsLTI1ODMyNzI5
MCwtODUwODA0NjgyLC0xNDQ0ODIzMzM3LC02MDU0NDYwODEsLT
EyNTkyNTA3MjcsLTE2OTIwMzY3NjMsMjAxMTkwODI3NiwtNDQ4
ODkzMjM3LDYxODA0NDUyLC0yMDk4OTU1MTc4LC05MDg4ODM4MT
YsMTMxNjA0OTQ4OCwtNzEyNDEyNjIxLC0xNjQ1OTkzMjU5LC0x
MTMxNjgwODAzXX0=
-->