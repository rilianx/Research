{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XS4st5usqTLN"
   },
   "outputs": [],
   "source": [
    "#@title **Main**\n",
    "from functions import *\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    " \n",
    "# Evitar truncar data mostrada al usar jupyter notebook\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    " \n",
    "# Constante que aloja el diccionario JSON con toda la data\n",
    "DATA = None\n",
    "\n",
    "# Obtener data JSON\n",
    "if os.path.exists('./out/dataout.json'):\n",
    "    DATA = json.load(open('./out/dataout.json', 'r'))\n",
    "else:\n",
    "    data_url = urlopen('http://nutriexcel.cl/UMDU/dataout_v2.json')\n",
    "    DATA = json.loads(data_url.read())\n",
    " \n",
    "# Labels base de las columnas\n",
    "LABELS_BASE = {\n",
    "    # Parámetros del alumno (Target)\n",
    "    'p1':                            ['p1'],\n",
    "    'p2':                            ['p2'],\n",
    "    'np':                            ['np'],\n",
    "    'p1p2':                          ['p1p2'], # Promedio p1p2 y p2p2\n",
    "    'p2p2':                          ['p2p2'],\n",
    "    \n",
    "    # Parámetros del laboratorio (Features)\n",
    "    'grade':                         ['g_lab#'],\n",
    "    'attempts':                      ['a_lab#'],\n",
    "    'usedtime':                      ['ut_lab#'],\n",
    "    'activetime':                    ['act_lab#'],\n",
    "    'disconnections':                ['dis_lab#'],      # log\n",
    "    'compilationtime':               ['ct_lab#'],\n",
    "    'runtimedebuggingtime':          ['rt_lab#'],\n",
    "    'compilationtimeratio':          ['ctr_lab#'],\n",
    "    'runtimedebuggingtimeratio':     ['rtr_lab#'],\n",
    "    'errorsreductionratio':          ['err_lab#'],\n",
    "    'compilationerrorsratio':        ['cer_lab#'],\n",
    "    'activequartiles':               ['actq1_lab#','actq2_lab#','actq3_lab#'],\n",
    "    'questionsdifficulty':           ['qd$_lab#'],\n",
    "    'questionsgrades':               ['qg$_lab#'],      # Promedio\n",
    "    'questionsattempts':             ['qat$_lab#'],     # Sumar - Max   # log\n",
    "    'questionsactivetime':           ['qact$_lab#'],    # Promedio\n",
    "    'questionsavgtime':              ['qavt$_lab#'],    # Promedio\n",
    "    'questionsmaxerrors':            ['qme$_lab#'],     # Max\n",
    "    'questionsmaxconsecutiveerrors': ['qmce$_lab#'],    # Max\n",
    "    'questionsmaxsimilarityratio':   ['qmsr$_lab#'],    # Promedio\n",
    "    'questionscorrectness':          ['qc$_lab#']       # Promedio\n",
    "}\n",
    " \n",
    " \n",
    "# Cantidad de preguntas por lab\n",
    "LABS_LENGTHS = {\n",
    "    '1': 7,\n",
    "    '2': 6,\n",
    "    '3': 6,\n",
    "    '4': 5,\n",
    "    '5': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3wJdhxdprjJM"
   },
   "outputs": [],
   "source": [
    "#@title **Data preparation**\n",
    "\n",
    "# Get dataframe\n",
    "datalab1_all = get_custom_dataframe(DATA, [1], ['p1','p2'], 'all', labels=True, index=None)\n",
    "\n",
    "datalab1 = copy.deepcopy(datalab1_all)\n",
    "\n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab1, 'qd?')\n",
    "# Group columns\n",
    "datalab1_all = apply(datalab1_all, ['p1','p2'], statistics.mean)\n",
    "datalab1 = apply(datalab1, ['p1','p2'], statistics.mean)\n",
    "datalab1 = apply(datalab1, 'dis_lab1', norm_log)\n",
    "datalab1 = apply(datalab1, 'qg?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qat?', sum, replace=False)\n",
    "datalab1 = apply(datalab1, 'sum(qat$_lab1)', norm_log, replace=False)\n",
    "datalab1 = apply(datalab1, 'qat?', max)\n",
    "datalab1 = apply(datalab1, 'qact?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qavt?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qme?', max)\n",
    "datalab1 = apply(datalab1, 'qmce?', max)\n",
    "datalab1 = apply(datalab1, 'qmsr?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qc?', statistics.mean)\n",
    "aux = datalab1['act_lab1'] / datalab1['sum(qat$_lab1)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab1['avgtime_lab1'] = aux\n",
    "datalab1 = datalab1.round(4)\n",
    " \n",
    " \n",
    "# Get dataframe\n",
    "datalab2_all = get_custom_dataframe(DATA, [2], ['p1','p2'], 'all', labels=True, index=None)\n",
    " \n",
    "datalab2 = copy.deepcopy(datalab2_all)\n",
    " \n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab2, 'qd?')\n",
    "# Group columns\n",
    "datalab2_all = apply(datalab2_all, ['p1','p2'], statistics.mean)\n",
    "datalab2 = apply(datalab2, ['p1','p2'], statistics.mean)\n",
    "datalab2 = apply(datalab2, 'dis_lab2', norm_log)\n",
    "datalab2 = apply(datalab2, 'qg?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qat?', sum, replace=False)\n",
    "datalab2 = apply(datalab2, 'sum(qat$_lab2)', norm_log, replace=False)\n",
    "datalab2 = apply(datalab2, 'qat?', max)\n",
    "datalab2 = apply(datalab2, 'qact?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qavt?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qme?', max)\n",
    "datalab2 = apply(datalab2, 'qmce?', max)\n",
    "datalab2 = apply(datalab2, 'qmsr?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qc?', statistics.mean)\n",
    "aux = datalab2['act_lab2'] / datalab2['sum(qat$_lab2)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab2['avgtime_lab2'] = aux\n",
    "datalab2 = datalab2.round(4)\n",
    " \n",
    " \n",
    "# Get dataframe\n",
    "datalab3_all = get_custom_dataframe(DATA, [3], ['p1','p2'], 'all', labels=True, index=None)\n",
    " \n",
    "datalab3 = copy.deepcopy(datalab3_all)\n",
    " \n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab3, 'qd?')\n",
    "# Group columns\n",
    "datalab3_all = apply(datalab3_all, ['p1','p2'], statistics.mean)\n",
    "datalab3 = apply(datalab3, ['p1','p2'], statistics.mean)\n",
    "datalab3 = apply(datalab3, 'dis_lab3', norm_log)\n",
    "datalab3 = apply(datalab3, 'qg?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qat?', sum, replace=False)\n",
    "datalab3 = apply(datalab3, 'sum(qat$_lab3)', norm_log, replace=False)\n",
    "datalab3 = apply(datalab3, 'qat?', max)\n",
    "datalab3 = apply(datalab3, 'qact?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qavt?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qme?', max)\n",
    "datalab3 = apply(datalab3, 'qmce?', max)\n",
    "datalab3 = apply(datalab3, 'qmsr?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qc?', statistics.mean)\n",
    "aux = datalab3['act_lab3'] / datalab3['sum(qat$_lab3)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab3['avgtime_lab3'] = aux\n",
    "datalab3 = datalab3.round(4)\n",
    " \n",
    " \n",
    "# Get dataframe\n",
    "datalab4_all = get_custom_dataframe(DATA, [4], ['p1','p2'], 'all', labels=True, index=None)\n",
    " \n",
    "datalab4 = copy.deepcopy(datalab4_all)\n",
    " \n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab4, 'qd?')\n",
    "# Group columns\n",
    "datalab4_all = apply(datalab4_all, ['p1','p2'], statistics.mean)\n",
    "datalab4 = apply(datalab4, ['p1','p2'], statistics.mean)\n",
    "datalab4 = apply(datalab4, 'dis_lab4', norm_log)\n",
    "datalab4 = apply(datalab4, 'qg?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qat?', sum, replace=False)\n",
    "datalab4 = apply(datalab4, 'sum(qat$_lab4)', norm_log, replace=False)\n",
    "datalab4 = apply(datalab4, 'qat?', max)\n",
    "datalab4 = apply(datalab4, 'qact?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qavt?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qme?', max)\n",
    "datalab4 = apply(datalab4, 'qmce?', max)\n",
    "datalab4 = apply(datalab4, 'qmsr?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qc?', statistics.mean)\n",
    "aux = datalab4['act_lab4'] / datalab4['sum(qat$_lab4)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab4['avgtime_lab4'] = aux\n",
    "datalab4 = datalab4.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ir0fyIzcWvwt"
   },
   "outputs": [],
   "source": [
    "#@title **Parameters**\n",
    "\n",
    "# Objective vector\n",
    "TARGET = 'mean(p$)'\n",
    "NORM_TYPE = 'col'\n",
    "N_FEATURES = 5\n",
    " \n",
    " \n",
    "# Import needed libraries ----------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "random_state = None # Random state for train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qo3ef38Mzspm"
   },
   "outputs": [],
   "source": [
    "#@title **Scale features**\n",
    " \n",
    "# Scale features -------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "scaler3 = StandardScaler()\n",
    "scaler4 = StandardScaler()\n",
    "scaler_all = StandardScaler()\n",
    "\n",
    "datalab1 = datalab1[[TARGET]].join(pd.DataFrame(scaler1.fit_transform(datalab1), columns=datalab1.columns)[datalab1.columns[1:]])\n",
    "datalab2 = datalab2[[TARGET]].join(pd.DataFrame(scaler2.fit_transform(datalab2), columns=datalab2.columns)[datalab2.columns[1:]])\n",
    "datalab3 = datalab3[[TARGET]].join(pd.DataFrame(scaler3.fit_transform(datalab3), columns=datalab3.columns)[datalab3.columns[1:]])\n",
    "datalab4 = datalab4[[TARGET]].join(pd.DataFrame(scaler4.fit_transform(datalab4), columns=datalab4.columns)[datalab4.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x-775imysfLt"
   },
   "outputs": [],
   "source": [
    "#@title **Grid/Random-SearchCV process**   \n",
    " \n",
    "def run_process(dataset, grid_cv, target=TARGET):\n",
    "    X, y = dataset.drop(target, axis=1), np.array(dataset[target])\n",
    "   \n",
    "    grid_cv.fit(X,y)\n",
    "    print('R2:', max(grid_cv.cv_results_['mean_test_score']))\n",
    "    \n",
    "    try:\n",
    "        selected_features = X.columns[grid_cv.best_estimator_.steps[0][-1].get_support()]\n",
    "    except:\n",
    "        return list(dataset.columns[1:])\n",
    "    \n",
    "    return list(selected_features)\n",
    "    \n",
    "def run_process_obsolete(dataset, grid_cv, target=TARGET):\n",
    "    X, y = dataset.drop(target, axis=1), np.array(dataset[target])\n",
    "   \n",
    "    grid_cv.fit(X,y)\n",
    " \n",
    "    try:\n",
    "        print('R2-test-fit:', max(grid_cv.cv_results_['mean_test_score']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        grid_cv.best_estimator_.fit(X_train, y_train)\n",
    "        print('R2-test', grid_cv.best_estimator_.score(X_test, y_test))\n",
    "        print('MSE-test', metrics.mean_squared_error(y_test,grid_cv.best_estimator_.predict(X_test)))\n",
    "\n",
    "        print('Best params:', grid_cv.best_params_)\n",
    "\n",
    "        selected_features = X.columns[grid_cv.best_estimator_.steps[0][-1].get_support()]\n",
    "        print('Selected features:', list(selected_features))\n",
    "\n",
    "        return list(selected_features)\n",
    "    except:\n",
    "        return list(dataset.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A9u_CRdMRu8W"
   },
   "outputs": [],
   "source": [
    "#@title **SVR - Recursive Features Elimination**\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "sel_estimator = SVR(kernel='linear')\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = SVR()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'sel__n_features_to_select' : [5],\n",
    "    'sel__step'                 : [1,2],\n",
    "    'est__C'                    : [0.01,0.1,1],\n",
    "    'est__gamma'                : ['scale','auto'],\n",
    "    'est__kernel'               : ['linear','poly','rbf']\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqNhUjWlVVV8",
    "outputId": "8dcfc3d2-84d4-4aa4-ff2d-8182c750c106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.008046114472525257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_lab1', 'actq2_lab1', 'actq3_lab1', 'mean(qg$_lab1)', 'mean(qmsr$_lab1)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab1_shuffle = datalab1.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_svr_1 = run_process(datalab1_shuffle,grid_svr)\n",
    "selected_features_svr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LH-_p_9fcYu5",
    "outputId": "d6e9505e-d38c-448a-856a-ebf6f289dbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   31.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.03677130801986146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab2',\n",
       " 'mean(qg$_lab2)',\n",
       " 'mean(qact$_lab2)',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'sum(qat$_lab2)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab2_shuffle = datalab2.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_svr_2 = run_process(datalab2_shuffle,grid_svr)\n",
    "selected_features_svr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3gVTJjpcY8l",
    "outputId": "39939876-2094-46b7-dac3-d50b92844d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   30.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.12918450879232526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab3',\n",
       " 'cer_lab3',\n",
       " 'mean(qg$_lab3)',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'norm_log(sum(qat$_lab3))']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab3_shuffle = datalab3.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_svr_3 = run_process(datalab3_shuffle,grid_svr)\n",
    "selected_features_svr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SuqwJklcZHe",
    "outputId": "0d9ff0f7-3e8d-42ee-8a80-71b73c11e025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.2190664446977674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_lab4',\n",
       " 'a_lab4',\n",
       " 'cer_lab4',\n",
       " 'mean(qmsr$_lab4)',\n",
       " 'norm_log(sum(qat$_lab4))']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab4_shuffle = datalab4.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_svr_4 = run_process(datalab4_shuffle,grid_svr)\n",
    "selected_features_svr_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ky4EgpioKcvl"
   },
   "outputs": [],
   "source": [
    "estimator = SVR()\n",
    "\n",
    "params = {\n",
    "    'C'         : [0.01,0.1,1],\n",
    "    'gamma'     : ['scale','auto'],\n",
    "    'kernel'    : ['linear','poly','rbf']\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(estimator=estimator,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QVGBRMfeGOj",
    "outputId": "413497c2-4395-40e5-845f-4f24ca9b20e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.08083328709952423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_lab1',\n",
       " 'actq2_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qg$_lab1)',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'rt_lab2',\n",
       " 'mean(qg$_lab2)',\n",
       " 'mean(qact$_lab2)',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'sum(qat$_lab2)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinacion lab 1 y 2 \n",
    "dataset = datalab1[[TARGET] + selected_features_svr_1].join(datalab2[selected_features_svr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXcAqOUDNbZH",
    "outputId": "979f4a20-0d77-4289-d043-8f35b3c764a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.15100361966348766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_lab1',\n",
       " 'actq2_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qg$_lab1)',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'rt_lab2',\n",
       " 'mean(qg$_lab2)',\n",
       " 'mean(qact$_lab2)',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'sum(qat$_lab2)',\n",
       " 'act_lab3',\n",
       " 'cer_lab3',\n",
       " 'mean(qg$_lab3)',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'norm_log(sum(qat$_lab3))']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinacion lab 1, 2 y 3\n",
    "dataset = datalab1[[TARGET] + selected_features_svr_1].join(datalab2[selected_features_svr_2]).join(datalab3[selected_features_svr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0nWWtKHesiI",
    "outputId": "a13739a4-a0f9-4adb-ece3-db935f1e49d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.26583993519783283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_lab1',\n",
       " 'actq2_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qg$_lab1)',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'rt_lab2',\n",
       " 'mean(qg$_lab2)',\n",
       " 'mean(qact$_lab2)',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'sum(qat$_lab2)',\n",
       " 'act_lab3',\n",
       " 'cer_lab3',\n",
       " 'mean(qg$_lab3)',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'norm_log(sum(qat$_lab3))',\n",
       " 'g_lab4',\n",
       " 'a_lab4',\n",
       " 'cer_lab4',\n",
       " 'mean(qmsr$_lab4)',\n",
       " 'norm_log(sum(qat$_lab4))']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinacion lab 1, 2 , 3 y 4\n",
    "dataset = datalab1[[TARGET] + selected_features_svr_1].join(datalab2[selected_features_svr_2]).join(datalab3[selected_features_svr_3]).join(datalab4[selected_features_svr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlwVnFigPsii",
    "outputId": "b5c44930-e938-4e46-c6f5-5744f4239f8a"
   },
   "outputs": [],
   "source": [
    "#@title **Random Forest Regressor** \n",
    "\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    " \n",
    "# GradientBoostingRegressor / RandomForestRegressor / SVR(kernel='linear')\n",
    "sel_estimator = GradientBoostingRegressor(random_state=1)\n",
    "#sel_estimator = GradientBoostingRegressor(random_state=random_state) \n",
    "# RFE / SelectFromModel\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = RandomForestRegressor(random_state=1, n_jobs=-1)\n",
    "#estimator = RandomForestRegressor(random_state=random_state, n_jobs=-1)\n",
    "\n",
    " \n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    " \n",
    "params = {\n",
    "    'sel__estimator__learning_rate': [0.05,0.1,0.2],\n",
    "    'sel__n_features_to_select'    : [5],\n",
    "    'est__n_estimators'            : [50,100,200,400],\n",
    "    'est__criterion'               : ['mse','mae'],\n",
    "    'est__max_features'            : ['auto','sqrt','log2']\n",
    "}\n",
    " \n",
    "grid_rfr = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "popqonA92_Wk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.08559909492717728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1', 'rtr_lab1', 'actq1_lab1', 'actq3_lab1', 'mean(qc$_lab1)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab1_shuffle = datalab1.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_rfr_1 = run_process(datalab1_shuffle,grid_rfr)\n",
    "selected_features_rfr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.03735556481679305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtr_lab2', 'actq1_lab2', 'actq2_lab2', 'mean(qc$_lab2)', 'avgtime_lab2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab2_shuffle = datalab2.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_rfr_2 = run_process(datalab2_shuffle,grid_rfr)\n",
    "selected_features_rfr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.0970994300785136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cer_lab3', 'actq1_lab3', 'actq2_lab3', 'max(qat$_lab3)', 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab3_shuffle = datalab3.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_rfr_3 = run_process(datalab3_shuffle,grid_rfr)\n",
    "selected_features_rfr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.15544919898639079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ut_lab4', 'cer_lab4', 'actq2_lab4', 'mean(qg$_lab4)', 'mean(qact$_lab4)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab4_shuffle = datalab4.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_rfr_4 = run_process(datalab4_shuffle,grid_rfr)\n",
    "selected_features_rfr_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(random_state=1, n_jobs=-1)\n",
    " \n",
    "params = {\n",
    "    'n_estimators'  : [50,100,200,400],\n",
    "    'criterion'     : ['mse','mae'],\n",
    "    'max_features'  : ['auto','sqrt','log2']\n",
    "}\n",
    " \n",
    "grid_rfr = GridSearchCV(estimator=estimator,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   57.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.060978454463522305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios\n",
    "dataset = datalab1[[TARGET] + selected_features_rfr_1].join(datalab2[selected_features_rfr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.16840420101769527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq2_lab3',\n",
       " 'max(qat$_lab3)',\n",
       " 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1[[TARGET] + selected_features_rfr_1].join(datalab2[selected_features_rfr_2]).join(datalab3[selected_features_rfr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   59.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.2619950206533569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq2_lab3',\n",
       " 'max(qat$_lab3)',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'ut_lab4',\n",
       " 'cer_lab4',\n",
       " 'actq2_lab4',\n",
       " 'mean(qg$_lab4)',\n",
       " 'mean(qact$_lab4)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1[[TARGET] + selected_features_rfr_1].join(datalab2[selected_features_rfr_2]).join(datalab3[selected_features_rfr_3]).join(datalab4[selected_features_rfr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-aZZOF1UtU6",
    "outputId": "8249eee6-0f17-45cc-9325-9e2b52aea6c5"
   },
   "outputs": [],
   "source": [
    "#@title **Linear Regression**\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "# GradientBoostingRegressor / RandomForestRegressor / SVR(kernel='linear')\n",
    "sel_estimator = GradientBoostingRegressor(random_state=1)\n",
    " \n",
    "# RFE / SelectFromModel\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    " \n",
    "# params = {'est__n_jobs': [-1], \n",
    "#           'est__normalize': [True], \n",
    "#           'sel__estimator__learning_rate': [0.1], \n",
    "#           'sel__estimator__n_estimators': [100], \n",
    "#           'sel__max_features': [10], \n",
    "#           'sel__prefit': [False]}\n",
    "\n",
    "params = {\n",
    "    'sel__n_features_to_select' : [5],\n",
    "    'sel__step'                 : [1,2],\n",
    "    'est__n_jobs'               : [-1],\n",
    "}\n",
    " \n",
    "grid_lr = GridSearchCV(estimator=pipe,\n",
    "                       param_grid=params,\n",
    "                       scoring='r2',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1,\n",
    "                       return_train_score=True,\n",
    "                       cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnZrJ-xcvqPd",
    "outputId": "66783e5a-65cb-4e5f-b3cc-1a7313563e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.028609160426679003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1', 'rtr_lab1', 'actq1_lab1', 'actq3_lab1', 'mean(qc$_lab1)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab1_shuffle = datalab1.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_1 = run_process(datalab1_shuffle,grid_lr)\n",
    "selected_features_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROQntNx6vq45",
    "outputId": "98d3791c-7e81-4f0f-b478-59d5eb5549ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.04318641891908598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtr_lab2', 'actq1_lab2', 'actq2_lab2', 'mean(qc$_lab2)', 'avgtime_lab2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab2_shuffle = datalab2.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_2 = run_process(datalab2_shuffle,grid_lr)\n",
    "selected_features_lr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNlQ6dJovrQ2",
    "outputId": "70f872d5-d583-4527-edfc-36576b700bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.00904676912959267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cer_lab3', 'actq1_lab3', 'actq2_lab3', 'max(qat$_lab3)', 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab3_shuffle = datalab3.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_3 = run_process(datalab3_shuffle,grid_lr)\n",
    "selected_features_lr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTGhXVnavrVD",
    "outputId": "ba0581b1-00d4-448f-bb34-995320c828eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.1168873333934279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ut_lab4', 'cer_lab4', 'actq2_lab4', 'mean(qg$_lab4)', 'mean(qact$_lab4)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab4_shuffle = datalab4.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_4 = run_process(datalab4_shuffle,grid_lr)\n",
    "selected_features_lr_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFgXHF3NvraA",
    "outputId": "ad41e16f-b1e6-4d4e-8669-7ad95c416e92"
   },
   "outputs": [],
   "source": [
    "estimator = LinearRegression()\n",
    " \n",
    "params = {\n",
    "    'n_jobs'    : [-1],\n",
    "}\n",
    " \n",
    "grid_lr = GridSearchCV(estimator=estimator,\n",
    "                       param_grid=params,\n",
    "                       scoring='r2',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1,\n",
    "                       return_train_score=True,\n",
    "                       cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UN85lqL5vriT",
    "outputId": "0a848233-eed6-4fc1-ef46-6e315a81d2dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "R2: 0.029536203962807196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1 y 2\n",
    "dataset = datalab1[[TARGET] + selected_features_lr_1].join(datalab2[selected_features_lr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8kRytTRvrmp",
    "outputId": "b620a7af-881a-4c12-fc4f-1d436a715250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "R2: 0.03890986982868912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq2_lab3',\n",
       " 'max(qat$_lab3)',\n",
       " 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1, 2 y 3\n",
    "dataset = datalab1[[TARGET] + selected_features_lr_1].join(datalab2[selected_features_lr_2]).join(datalab3[selected_features_lr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRx6DZz8vrrD",
    "outputId": "175d92d1-bda0-482f-edab-8d1de3c3a7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "R2: 0.14070597606982785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab1',\n",
       " 'rtr_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qc$_lab1)',\n",
       " 'rtr_lab2',\n",
       " 'actq1_lab2',\n",
       " 'actq2_lab2',\n",
       " 'mean(qc$_lab2)',\n",
       " 'avgtime_lab2',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq2_lab3',\n",
       " 'max(qat$_lab3)',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'ut_lab4',\n",
       " 'cer_lab4',\n",
       " 'actq2_lab4',\n",
       " 'mean(qg$_lab4)',\n",
       " 'mean(qact$_lab4)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1, 2, 3 y 4\n",
    "dataset = datalab1[[TARGET] + selected_features_lr_1].join(datalab2[selected_features_lr_2]).join(datalab3[selected_features_lr_3]).join(datalab4[selected_features_lr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "consoleUMDU - modelos x.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
