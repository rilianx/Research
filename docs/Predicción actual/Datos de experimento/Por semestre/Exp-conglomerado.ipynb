{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b1 import *\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    " \n",
    "# Evitar truncar data mostrada al usar jupyter notebook\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    " \n",
    "# Constante que aloja el diccionario JSON con toda la data\n",
    "DATA = None\n",
    "\n",
    "# Obtener data JSON\n",
    "if os.path.exists('./out/dataout.json'):\n",
    "    DATA = json.load(open('./out/dataout.json', 'r'))\n",
    "else:\n",
    "    data_url = urlopen('http://nutriexcel.cl/UMDU/dataout_v2.json')\n",
    "    DATA = json.loads(data_url.read())\n",
    " \n",
    "# Labels base de las columnas\n",
    "LABELS_BASE = {\n",
    "    # Parámetros del alumno (Target)\n",
    "    'p1':                            ['p1'],\n",
    "    'p2':                            ['p2'],\n",
    "    'np':                            ['np'],\n",
    "    'p1p2':                          ['p1p2'], # Promedio p1p2 y p2p2\n",
    "    'p2p2':                          ['p2p2'],\n",
    "    \n",
    "    # Parámetros del laboratorio (Features)\n",
    "    'grade':                         ['g_lab#'],\n",
    "    'attempts':                      ['a_lab#'],\n",
    "    'usedtime':                      ['ut_lab#'],\n",
    "    'activetime':                    ['act_lab#'],\n",
    "    'disconnections':                ['dis_lab#'],      # log\n",
    "    'compilationtime':               ['ct_lab#'],\n",
    "    'runtimedebuggingtime':          ['rt_lab#'],\n",
    "    'compilationtimeratio':          ['ctr_lab#'],\n",
    "    'runtimedebuggingtimeratio':     ['rtr_lab#'],\n",
    "    'errorsreductionratio':          ['err_lab#'],\n",
    "    'compilationerrorsratio':        ['cer_lab#'],\n",
    "    'activequartiles':               ['actq1_lab#','actq2_lab#','actq3_lab#'],\n",
    "    'questionsdifficulty':           ['qd$_lab#'],\n",
    "    'questionsgrades':               ['qg$_lab#'],      # Promedio\n",
    "    'questionsattempts':             ['qat$_lab#'],     # Sumar - Max   # log\n",
    "    'questionsactivetime':           ['qact$_lab#'],    # Promedio\n",
    "    'questionsavgtime':              ['qavt$_lab#'],    # Promedio\n",
    "    'questionsmaxerrors':            ['qme$_lab#'],     # Max\n",
    "    'questionsmaxconsecutiveerrors': ['qmce$_lab#'],    # Max\n",
    "    'questionsmaxsimilarityratio':   ['qmsr$_lab#'],    # Promedio\n",
    "    'questionscorrectness':          ['qc$_lab#']       # Promedio\n",
    "}\n",
    " \n",
    " \n",
    "# Cantidad de preguntas por lab\n",
    "LABS_LENGTHS = {\n",
    "    '1': 7,\n",
    "    '2': 6,\n",
    "    '3': 6,\n",
    "    '4': 5,\n",
    "    '5': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curso  7 : 55\n",
      "curso  13 : 22\n",
      "curso  19 : 54\n",
      "curso  24 : 28\n",
      "curso  30 : 53\n",
      "curso  36 : 41\n",
      "total: 253\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for id in DATA[\"courses\"]:\n",
    "    students=len(DATA[\"courses\"][id][\"students\"])\n",
    "    total+=students\n",
    "    print(\"curso \",id,\":\",students)\n",
    "print(\"total:\",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Parameters**\n",
    "\n",
    "# Objective vector\n",
    "TARGET = 'np'\n",
    "NORM_TYPE = 'col'\n",
    "N_FEATURES = 5\n",
    " \n",
    " \n",
    "# Import needed libraries ----------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "random_state = None # Random state for train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "13\n",
      "19\n",
      "24\n",
      "30\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# CursoData retorna el curso de los alumnos del lab Correspondiente\n",
    "datalab1_all,cursoData = get_custom_dataframe(DATA, [1], ['np'], 'all', labels=True, index=None)\n",
    "\n",
    "\n",
    "#cursoData[cursoData.index in datalab1_al]\n",
    "#print(datalab1_al)\n",
    "\n",
    "\n",
    "#@title **Data preparation**\n",
    "\n",
    "datalab1 = copy.deepcopy(datalab1_all)\n",
    "\n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab1, 'qd?')\n",
    "# Group columns\n",
    "datalab1 = apply(datalab1, 'dis_lab1', norm_log)\n",
    "datalab1 = apply(datalab1, 'qg?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qat?', sum, replace=False)\n",
    "datalab1 = apply(datalab1, 'sum(qat$_lab1)', norm_log, replace=False)\n",
    "datalab1 = apply(datalab1, 'qat?', max)\n",
    "datalab1 = apply(datalab1, 'qact?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qavt?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qme?', max)\n",
    "datalab1 = apply(datalab1, 'qmce?', max)\n",
    "datalab1 = apply(datalab1, 'qmsr?', statistics.mean)\n",
    "datalab1 = apply(datalab1, 'qc?', statistics.mean)\n",
    "aux = datalab1['act_lab1'] / datalab1['sum(qat$_lab1)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab1['avgtime_lab1'] = aux\n",
    "datalab1 = datalab1.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma a dataframe la info de ese curso en particular\n",
    "cursoDF = pd.DataFrame(cursoData,columns=['curso'])\n",
    "\n",
    "# Se concatenan los dos dataframes \n",
    "dfFinlab1 = pd.concat([datalab1,cursoDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso7 = dfFinlab1.loc[dfFinlab1['curso']=='7']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene la columna con el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso7.reset_index()[TARGET])\n",
    "\n",
    "# Se obtiene los datos del curso X para el lab Y normalizados Excluyendo la fila mean(p$p2)\n",
    "# ------------               Función que normaliza la data      , el nombre de las col a colocar en el DF  [desde cual columna hasta cual]\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso7),columns=dfLab1Curso7.columns)[dfLab1Curso7.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc7 = pd.concat([promCurso,DFnormalizado],axis=1)\n",
    "#datalab1Normc7\n",
    "\n",
    "# Sentencia anterior\n",
    "#datalab1Normc7 = dfLab1Curso7[['mean(p$p2)']].join(pd.DataFrame(scaler1.fit_transform(dfLab1Curso7), columns=dfLab1Curso7.columns)[dfLab1Curso7.columns[1:26]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso13 = dfFinlab1.loc[dfFinlab1['curso']=='13']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso13.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso13),columns=dfLab1Curso13.columns)[dfLab1Curso13.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc13 = pd.concat([promCurso,DFnormalizado],axis=1)\n",
    "\n",
    "\n",
    "# Sentencia anterior\n",
    "#datalab1Normc13 = dfLab1Curso13[['mean(p$p2)']].join(pd.DataFrame(scaler2.fit_transform(dfLab1Curso13), columns=dfLab1Curso13.columns)[dfLab1Curso13.columns[1:26]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso19 = dfFinlab1.loc[dfFinlab1['curso']=='19']\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso19.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso19),columns=dfLab1Curso19.columns)[dfLab1Curso19.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc19 = pd.concat([promCurso,DFnormalizado],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso24 = dfFinlab1.loc[dfFinlab1['curso']=='24']\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso24.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso24),columns=dfLab1Curso24.columns)[dfLab1Curso24.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc24 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso30 = dfFinlab1.loc[dfFinlab1['curso']=='30']\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso30.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso30),columns=dfLab1Curso30.columns)[dfLab1Curso30.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc30 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab1Curso36 = dfFinlab1.loc[dfFinlab1['curso']=='36']\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab1Curso36.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab1Curso36),columns=dfLab1Curso36.columns)[dfLab1Curso36.columns[1:26]]\n",
    "                       \n",
    "datalab1Normc36 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se unen los datos del laboratorio 1\n",
    "datalab1_norm = pd.concat([datalab1Normc7,datalab1Normc13,datalab1Normc19,datalab1Normc24,datalab1Normc30,datalab1Normc36],axis=0)\n",
    "datalab1_norm = datalab1_norm.reset_index(drop = True)\n",
    "#datalab1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "13\n",
      "19\n",
      "24\n",
      "30\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#LAB 2\n",
    "datalab2_all,cursoData = get_custom_dataframe(DATA, [2], ['np'], 'all', labels=True, index=None)\n",
    " \n",
    "datalab2 = copy.deepcopy(datalab2_all)\n",
    " \n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab2, 'qd?')\n",
    "# Group columns\n",
    "datalab2 = apply(datalab2, 'dis_lab2', norm_log)\n",
    "datalab2 = apply(datalab2, 'qg?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qat?', sum, replace=False)\n",
    "datalab2 = apply(datalab2, 'sum(qat$_lab2)', norm_log, replace=False)\n",
    "datalab2 = apply(datalab2, 'qat?', max)\n",
    "datalab2 = apply(datalab2, 'qact?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qavt?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qme?', max)\n",
    "datalab2 = apply(datalab2, 'qmce?', max)\n",
    "datalab2 = apply(datalab2, 'qmsr?', statistics.mean)\n",
    "datalab2 = apply(datalab2, 'qc?', statistics.mean)\n",
    "aux = datalab2['act_lab2'] / datalab2['sum(qat$_lab2)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab2['avgtime_lab2'] = aux\n",
    "datalab2 = datalab2.round(4)\n",
    "\n",
    "# Se transforma a dataframe la info de ese curso en particular\n",
    "cursoDF = pd.DataFrame(cursoData,columns=['curso'])\n",
    "\n",
    "# Se concatenan los dos dataframes \n",
    "dfFinlab2 = pd.concat([datalab2,cursoDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso7 = dfFinlab2.loc[dfFinlab2['curso']=='7']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso7.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso7),columns=dfLab2Curso7.columns)[dfLab2Curso7.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc7 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso13 = dfFinlab2.loc[dfFinlab2['curso']=='13']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso13.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso13),columns=dfLab2Curso13.columns)[dfLab2Curso13.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc13 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso19 = dfFinlab2.loc[dfFinlab2['curso']=='19']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso19.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso19),columns=dfLab2Curso19.columns)[dfLab2Curso19.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc19 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso24 = dfFinlab2.loc[dfFinlab2['curso']=='24']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso24.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso24),columns=dfLab2Curso24.columns)[dfLab2Curso24.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc24 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso30 = dfFinlab2.loc[dfFinlab2['curso']=='30']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso30.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso30),columns=dfLab2Curso30.columns)[dfLab2Curso30.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc30 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab2Curso36 = dfFinlab2.loc[dfFinlab2['curso']=='36']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab2Curso36.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab2Curso36),columns=dfLab2Curso36.columns)[dfLab2Curso36.columns[1:26]]\n",
    "                       \n",
    "datalab2Normc36 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se unen los datos del laboratorio 2\n",
    "datalab2_norm = pd.concat([datalab2Normc7,datalab2Normc13,datalab2Normc19,datalab2Normc24,datalab2Normc30,datalab2Normc36],axis=0)\n",
    "datalab2_norm = datalab2_norm.reset_index(drop = True)\n",
    "#datalab2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler1 = StandardScaler()\n",
    "#datalab2Normc7 = dfLab2Curso7[['mean(p$p2)']].join(pd.DataFrame(scaler1.fit_transform(dfLab2Curso7), columns=dfLab2Curso7.columns)[dfLab2Curso7.columns[1:26]]) \n",
    "#datalab2Normc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "13\n",
      "19\n",
      "24\n",
      "30\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#LAB 3\n",
    "\n",
    "datalab3_all,cursoData = get_custom_dataframe(DATA, [3], ['np'], 'all', labels=True, index=None)\n",
    "\n",
    "datalab3 = copy.deepcopy(datalab3_all)\n",
    " \n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab3, 'qd?')\n",
    "# Group columns\n",
    "datalab3 = apply(datalab3, 'dis_lab3', norm_log)\n",
    "datalab3 = apply(datalab3, 'qg?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qat?', sum, replace=False)\n",
    "datalab3 = apply(datalab3, 'sum(qat$_lab3)', norm_log, replace=False)\n",
    "datalab3 = apply(datalab3, 'qat?', max)\n",
    "datalab3 = apply(datalab3, 'qact?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qavt?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qme?', max)\n",
    "datalab3 = apply(datalab3, 'qmce?', max)\n",
    "datalab3 = apply(datalab3, 'qmsr?', statistics.mean)\n",
    "datalab3 = apply(datalab3, 'qc?', statistics.mean)\n",
    "aux = datalab3['act_lab3'] / datalab3['sum(qat$_lab3)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab3['avgtime_lab3'] = aux\n",
    "datalab3 = datalab3.round(4)\n",
    "\n",
    "# Se transforma a dataframe la info de ese curso en particular\n",
    "cursoDF = pd.DataFrame(cursoData,columns=['curso'])\n",
    "\n",
    "# Se concatenan los dos dataframes \n",
    "dfFinlab3 = pd.concat([datalab3,cursoDF],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso7 = dfFinlab3.loc[dfFinlab3['curso']=='7']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso7.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso7),columns=dfLab3Curso7.columns)[dfLab3Curso7.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc7 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso13 = dfFinlab3.loc[dfFinlab3['curso']=='13']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso13.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso13),columns=dfLab3Curso13.columns)[dfLab3Curso13.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc13 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso19 = dfFinlab3.loc[dfFinlab3['curso']=='19']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso19.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso19),columns=dfLab3Curso19.columns)[dfLab3Curso19.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc19 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso24 = dfFinlab3.loc[dfFinlab3['curso']=='24']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso24.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso24),columns=dfLab3Curso24.columns)[dfLab3Curso24.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc24 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso30 = dfFinlab3.loc[dfFinlab3['curso']=='30']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso30.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso30),columns=dfLab3Curso30.columns)[dfLab3Curso30.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc30 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab3Curso36 = dfFinlab3.loc[dfFinlab3['curso']=='36']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab3Curso36.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab3Curso36),columns=dfLab3Curso36.columns)[dfLab3Curso36.columns[1:26]]\n",
    "                       \n",
    "datalab3Normc36 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se unen los datos del laboratorio 3\n",
    "datalab3_norm = pd.concat([datalab3Normc7,datalab3Normc13,datalab3Normc19,datalab3Normc24,datalab3Normc30,datalab3Normc36],axis=0)\n",
    "datalab3_norm = datalab3_norm.reset_index(drop = True)\n",
    "#datalab3_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "13\n",
      "19\n",
      "24\n",
      "30\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#LAB 4\n",
    "\n",
    "datalab4_all,cursoData = get_custom_dataframe(DATA, [4], ['np'], 'all', labels=True, index=None)\n",
    "datalab4 = copy.deepcopy(datalab4_all)\n",
    "\n",
    "# Remove questionsdifficulty\n",
    "remove_col(datalab4, 'qd?')\n",
    "# Group columns\n",
    "datalab4 = apply(datalab4, 'dis_lab4', norm_log)\n",
    "datalab4 = apply(datalab4, 'qg?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qat?', sum, replace=False)\n",
    "datalab4 = apply(datalab4, 'sum(qat$_lab4)', norm_log, replace=False)\n",
    "datalab4 = apply(datalab4, 'qat?', max)\n",
    "datalab4 = apply(datalab4, 'qact?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qavt?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qme?', max)\n",
    "datalab4 = apply(datalab4, 'qmce?', max)\n",
    "datalab4 = apply(datalab4, 'qmsr?', statistics.mean)\n",
    "datalab4 = apply(datalab4, 'qc?', statistics.mean)\n",
    "aux = datalab4['act_lab4'] / datalab4['sum(qat$_lab4)']\n",
    "for i in range(len(aux)):\n",
    "    if not aux[i] > 0:\n",
    "        aux[i] = 0\n",
    "datalab4['avgtime_lab4'] = aux\n",
    "datalab4 = datalab4.round(4)\n",
    "\n",
    "# Se transforma a dataframe la info de ese curso en particular\n",
    "cursoDF = pd.DataFrame(cursoData,columns=['curso'])\n",
    "\n",
    "# Se concatenan los dos dataframes \n",
    "dfFinlab4 = pd.concat([datalab4,cursoDF],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso7 = dfFinlab4.loc[dfFinlab4['curso']=='7']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso7.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso7),columns=dfLab4Curso7.columns)[dfLab4Curso7.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc7 = pd.concat([promCurso,DFnormalizado],axis=1)\n",
    "#datalab4Normc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso13 = dfFinlab4.loc[dfFinlab4['curso']=='13']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso13.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso13),columns=dfLab4Curso13.columns)[dfLab4Curso13.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc13 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso19 = dfFinlab4.loc[dfFinlab4['curso']=='19']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso19.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso19),columns=dfLab4Curso19.columns)[dfLab4Curso19.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc19 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso24 = dfFinlab4.loc[dfFinlab4['curso']=='24']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso24.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso24),columns=dfLab4Curso24.columns)[dfLab4Curso24.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc24 = pd.concat([promCurso,DFnormalizado],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso30 = dfFinlab4.loc[dfFinlab4['curso']=='30']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso30.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso30),columns=dfLab4Curso30.columns)[dfLab4Curso30.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc30 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filtrar por curso\n",
    "dfLab4Curso36 = dfFinlab4.loc[dfFinlab4['curso']=='36']\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# Se obtiene el promedio del curso X\n",
    "promCurso = pd.DataFrame(dfLab4Curso36.reset_index()[TARGET])\n",
    "\n",
    "DFnormalizado = pd.DataFrame(scaler1.fit_transform(dfLab4Curso36),columns=dfLab4Curso36.columns)[dfLab4Curso36.columns[1:26]]\n",
    "                       \n",
    "datalab4Normc36 = pd.concat([promCurso,DFnormalizado],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se unen los datos del laboratorio 4\n",
    "datalab4_norm = pd.concat([datalab4Normc7,datalab4Normc13,datalab4Normc19,datalab4Normc24,datalab4Normc30,datalab4Normc36],axis=0)\n",
    "datalab4_norm = datalab4_norm.reset_index(drop = True)\n",
    "#datalab4_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Grid/Random-SearchCV process**   \n",
    " \n",
    "def run_process(dataset, grid_cv, target=TARGET):\n",
    "    X, y = dataset.drop(target, axis=1), np.array(dataset[target])\n",
    "   \n",
    "    grid_cv.fit(X,y)\n",
    "    print('R2:', max(grid_cv.cv_results_['mean_test_score']))\n",
    "    \n",
    "    try:\n",
    "        selected_features = X.columns[grid_cv.best_estimator_.steps[0][-1].get_support()]\n",
    "    except:\n",
    "        return list(dataset.columns[1:])\n",
    "    \n",
    "    return list(selected_features)\n",
    "    \n",
    "def run_process_obsolete(dataset, grid_cv, target=TARGET):\n",
    "    X, y = dataset.drop(target, axis=1), np.array(dataset[target])\n",
    "   \n",
    "    grid_cv.fit(X,y)\n",
    " \n",
    "    try:\n",
    "        print('R2-test-fit:', max(grid_cv.cv_results_['mean_test_score']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        grid_cv.best_estimator_.fit(X_train, y_train)\n",
    "        print('R2-test', grid_cv.best_estimator_.score(X_test, y_test))\n",
    "        print('MSE-test', metrics.mean_squared_error(y_test,grid_cv.best_estimator_.predict(X_test)))\n",
    "\n",
    "        print('Best params:', grid_cv.best_params_)\n",
    "\n",
    "        selected_features = X.columns[grid_cv.best_estimator_.steps[0][-1].get_support()]\n",
    "        print('Selected features:', list(selected_features))\n",
    "\n",
    "        return list(selected_features)\n",
    "    except:\n",
    "        return list(dataset.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **SVR - Recursive Features Elimination**\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "sel_estimator = SVR(kernel='linear')\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = SVR()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'sel__n_features_to_select' : [5],\n",
    "    'sel__step'                 : [1,2],\n",
    "    'est__C'                    : [0.01,0.1,1],\n",
    "    'est__gamma'                : ['scale','auto'],\n",
    "    'est__kernel'               : ['linear','poly','rbf']\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   32.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.009242189892908325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab1',\n",
       " 'cer_lab1',\n",
       " 'actq1_lab1',\n",
       " 'max(qme$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab1_shuffle = datalab1_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab1_shuffle = datalab1_shuffle[datalab1_shuffle.np>1]\n",
    "selected_features_svr_1 = run_process(datalab1_shuffle,grid_svr)\n",
    "selected_features_svr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   30.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.11254111977610262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab2', 'ctr_lab2', 'err_lab2', 'actq3_lab2', 'norm_log(sum(qat$_lab2))']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab2_shuffle = datalab2_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab2_shuffle = datalab2_shuffle[datalab2_shuffle.np>1]\n",
    "selected_features_svr_2 = run_process(datalab2_shuffle,grid_svr)\n",
    "selected_features_svr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalab3_shuffle = datalab3_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab3_shuffle = datalab3_shuffle[datalab3_shuffle.np>1]\n",
    "selected_features_svr_3 = run_process(datalab3_shuffle,grid_svr)\n",
    "selected_features_svr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   28.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.05321616870109906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['act_lab4', 'rt_lab4', 'rtr_lab4', 'cer_lab4', 'norm_log(sum(qat$_lab4))']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab4_shuffle = datalab4_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab4_shuffle = datalab4_shuffle[datalab4_shuffle.np>1]\n",
    "selected_features_svr_4 = run_process(datalab4_shuffle,grid_svr)\n",
    "selected_features_svr_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR()\n",
    "\n",
    "params = {\n",
    "    'C'         : [0.01,0.1,1],\n",
    "    'gamma'     : ['scale','auto'],\n",
    "    'kernel'    : ['linear','poly','rbf']\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(estimator=estimator,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.14536524631658831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab1',\n",
       " 'cer_lab1',\n",
       " 'actq1_lab1',\n",
       " 'max(qme$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rt_lab2',\n",
       " 'ctr_lab2',\n",
       " 'err_lab2',\n",
       " 'actq3_lab2',\n",
       " 'norm_log(sum(qat$_lab2))']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1_norm[[TARGET] + selected_features_svr_1].join(datalab2_norm[selected_features_svr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   10.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.2583306856030839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab1',\n",
       " 'cer_lab1',\n",
       " 'actq1_lab1',\n",
       " 'max(qme$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rt_lab2',\n",
       " 'ctr_lab2',\n",
       " 'err_lab2',\n",
       " 'actq3_lab2',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'ut_lab3',\n",
       " 'act_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'norm_log(sum(qat$_lab3))']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1_norm[[TARGET] + selected_features_svr_1].join(datalab2_norm[selected_features_svr_2]).join(datalab3_norm[selected_features_svr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.2451168627449464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab1',\n",
       " 'cer_lab1',\n",
       " 'actq1_lab1',\n",
       " 'max(qme$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rt_lab2',\n",
       " 'ctr_lab2',\n",
       " 'err_lab2',\n",
       " 'actq3_lab2',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'ut_lab3',\n",
       " 'act_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'norm_log(sum(qat$_lab3))',\n",
       " 'act_lab4',\n",
       " 'rt_lab4',\n",
       " 'rtr_lab4',\n",
       " 'cer_lab4',\n",
       " 'norm_log(sum(qat$_lab4))']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1_norm[[TARGET] + selected_features_svr_1].join(datalab2_norm[selected_features_svr_2]).join(datalab3_norm[selected_features_svr_3]).join(datalab4_norm[selected_features_svr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Random Forest Regressor** \n",
    "\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    " \n",
    "# GradientBoostingRegressor / RandomForestRegressor / SVR(kernel='linear')\n",
    "sel_estimator = GradientBoostingRegressor(random_state=1)\n",
    " \n",
    "# RFE / SelectFromModel\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = RandomForestRegressor(random_state=1, n_jobs=-1)\n",
    " \n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    " \n",
    "params = {\n",
    "    'sel__estimator__learning_rate': [0.05,0.1,0.2],\n",
    "    'sel__n_features_to_select'    : [5],\n",
    "    'est__n_estimators'            : [50,100,200,400],\n",
    "    'est__criterion'               : ['mse','mae'],\n",
    "    'est__max_features'            : ['auto','sqrt','log2']\n",
    "}\n",
    " \n",
    "grid_rfr = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.16291794440999158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab1_shuffle = datalab1_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab1_shuffle = datalab1_shuffle[datalab1_shuffle.np>1]\n",
    "#selected_features_rfr_1 = run_process(datalab1_shuffle,grid_rfr)\n",
    "selected_features_rfr_1 = ['rt_lab1', 'actq1_lab1', 'actq3_lab1', 'mean(qmsr$_lab1)', 'norm_log(sum(qat$_lab1))']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.12556668895087514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab2_shuffle = datalab2_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab2_shuffle=datalab2_shuffle[datalab2_shuffle.np>1]\n",
    "#selected_features_rfr_2 = run_process(datalab2_shuffle,grid_rfr)\n",
    "selected_features_rfr_2 = ['rtr_lab2', 'mean(qmsr$_lab2)', 'mean(qc$_lab2)', 'norm_log(sum(qat$_lab2))', 'avgtime_lab2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.21684577761353493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab3', 'cer_lab3', 'actq1_lab3', 'actq3_lab3', 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab3_shuffle = datalab3_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab3_shuffle=datalab3_shuffle[datalab3_shuffle.np>1]\n",
    "#selected_features_rfr_3 = run_process(datalab3_shuffle,grid_rfr)\n",
    "selected_features_rfr_3 = ['a_lab3', 'cer_lab3', 'actq1_lab3', 'actq3_lab3', 'mean(qmsr$_lab3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.04808627999715005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['norm_log(dis_lab4)',\n",
       " 'cer_lab4',\n",
       " 'max(qme$_lab4)',\n",
       " 'mean(qmsr$_lab4)',\n",
       " 'avgtime_lab4']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalab4_shuffle = datalab4_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "datalab4_shuffle=datalab4_shuffle[datalab4_shuffle.np>1]\n",
    "#selected_features_rfr_4 = run_process(datalab4_shuffle,grid_rfr)\n",
    "selected_features_rfr_4 = ['norm_log(dis_lab4)', 'cer_lab4', 'max(qme$_lab4)', 'mean(qmsr$_lab4)', 'avgtime_lab4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(random_state=1, n_jobs=-1)\n",
    " \n",
    "params = {\n",
    "    'n_estimators'  : [50,100,200,400],\n",
    "    'criterion'     : ['mse','mae'],\n",
    "    'max_features'  : ['auto','sqrt','log2']\n",
    "}\n",
    " \n",
    "grid_rfr = GridSearchCV(estimator=estimator,\n",
    "                        param_grid=params,\n",
    "                        scoring='r2',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features_rfr_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bb6167991fe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Combinación de laboratorios\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatalab1_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mselected_features_rfr_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatalab2_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_features_rfr_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdataset_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset_shuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_shuffle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_shuffle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrun_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_shuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_rfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_features_rfr_1' is not defined"
     ]
    }
   ],
   "source": [
    "#Combinación de laboratorios\n",
    "dataset = datalab1_norm[[TARGET] + selected_features_rfr_1].join(datalab2_norm[selected_features_rfr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.413248869913123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2',\n",
       " 'a_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq3_lab3',\n",
       " 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1_norm[[TARGET] + selected_features_rfr_1].join(datalab2_norm[selected_features_rfr_2]).join(datalab3_norm[selected_features_rfr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.45328232812119307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2',\n",
       " 'a_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq3_lab3',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'norm_log(dis_lab4)',\n",
       " 'cer_lab4',\n",
       " 'max(qme$_lab4)',\n",
       " 'mean(qmsr$_lab4)',\n",
       " 'avgtime_lab4']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datalab1_norm[[TARGET] + selected_features_rfr_1].join(datalab2_norm[selected_features_rfr_2]).join(datalab3_norm[selected_features_rfr_3]).join(datalab4_norm[selected_features_rfr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4988340093505541"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dataset_shuffle.drop(TARGET, axis=1), np.array(dataset_shuffle[TARGET])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "grid_rfr.best_estimator_.fit(X_train,y_train)\n",
    "ypred = grid_rfr.best_estimator_.predict(X_test)\n",
    "grid_rfr.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ypred,y_test)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_test')\n",
    "#plt.savefig('pruebas_rf_1234_0.3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02592353, 0.03787414, 0.02766525, 0.04312142, 0.02046497,\n",
       "       0.04677065, 0.05709156, 0.03863762, 0.03893699, 0.03634464,\n",
       "       0.09299988, 0.05971999, 0.06533319, 0.07990229, 0.08313161,\n",
       "       0.03884615, 0.04649068, 0.02701885, 0.04518106, 0.08854553])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfr.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Linear Regression**\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "# GradientBoostingRegressor / RandomForestRegressor / SVR(kernel='linear')\n",
    "sel_estimator = GradientBoostingRegressor(random_state=1)\n",
    " \n",
    "# RFE / SelectFromModel\n",
    "selector = RFE(sel_estimator)\n",
    "estimator = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', selector),\n",
    "    ('est', estimator)\n",
    "])\n",
    " \n",
    "# params = {'est__n_jobs': [-1], \n",
    "#           'est__normalize': [True], \n",
    "#           'sel__estimator__learning_rate': [0.1], \n",
    "#           'sel__estimator__n_estimators': [100], \n",
    "#           'sel__max_features': [10], \n",
    "#           'sel__prefit': [False]}\n",
    "\n",
    "params = {\n",
    "    'sel__n_features_to_select' : [5],\n",
    "    'sel__step'                 : [1,2],\n",
    "    'est__n_jobs'               : [-1],\n",
    "}\n",
    " \n",
    "grid_lr = GridSearchCV(estimator=pipe,\n",
    "                       param_grid=params,\n",
    "                       scoring='r2',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1,\n",
    "                       return_train_score=True,\n",
    "                       cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.059131668073848495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datalab1_shuffle = datalab1_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_1 = run_process(datalab1_shuffle,grid_lr)\n",
    "selected_features_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.05448532464032642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datalab2_shuffle = datalab2_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_2 = run_process(datalab2_shuffle,grid_lr)\n",
    "selected_features_lr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.11892293242188863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab3', 'cer_lab3', 'actq1_lab3', 'actq3_lab3', 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datalab3_shuffle = datalab3_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_3 = run_process(datalab3_shuffle,grid_lr)\n",
    "selected_features_lr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.10917990369638046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_lab4', 'cer_lab4', 'actq1_lab4', 'mean(qmsr$_lab4)', 'avgtime_lab4']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datalab4_shuffle = datalab4_norm.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "selected_features_lr_4 = run_process(datalab4_shuffle,grid_lr)\n",
    "selected_features_lr_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LinearRegression()\n",
    " \n",
    "params = {\n",
    "    'n_jobs'    : [-1],\n",
    "}\n",
    " \n",
    "grid_lr = GridSearchCV(estimator=estimator,\n",
    "                       param_grid=params,\n",
    "                       scoring='r2',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1,\n",
    "                       return_train_score=True,\n",
    "                       cv=KFold(n_splits=10, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.09100690803255038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1 y 2\n",
    "dataset = datalab1_norm[[TARGET] + selected_features_lr_1].join(datalab2_norm[selected_features_lr_2])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.1946749240437255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2',\n",
       " 'a_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq3_lab3',\n",
       " 'mean(qmsr$_lab3)']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1, 2 y 3\n",
    "dataset = datalab1_norm[[TARGET] + selected_features_lr_1].join(datalab2_norm[selected_features_lr_2]).join(datalab3_norm[selected_features_lr_3])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.16884636431415478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rt_lab1',\n",
       " 'actq1_lab1',\n",
       " 'actq3_lab1',\n",
       " 'mean(qmsr$_lab1)',\n",
       " 'norm_log(sum(qat$_lab1))',\n",
       " 'rtr_lab2',\n",
       " 'mean(qmsr$_lab2)',\n",
       " 'mean(qc$_lab2)',\n",
       " 'norm_log(sum(qat$_lab2))',\n",
       " 'avgtime_lab2',\n",
       " 'a_lab3',\n",
       " 'cer_lab3',\n",
       " 'actq1_lab3',\n",
       " 'actq3_lab3',\n",
       " 'mean(qmsr$_lab3)',\n",
       " 'a_lab4',\n",
       " 'cer_lab4',\n",
       " 'actq1_lab4',\n",
       " 'mean(qmsr$_lab4)',\n",
       " 'avgtime_lab4']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinación de laboratorios 1, 2, 3 y 4\n",
    "dataset = datalab1_norm[[TARGET] + selected_features_lr_1].join(datalab2_norm[selected_features_lr_2]).join(datalab3_norm[selected_features_lr_3]).join(datalab4_norm[selected_features_lr_4])\n",
    "dataset_shuffle = dataset.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "dataset_shuffle=dataset_shuffle[dataset_shuffle.np>1]\n",
    "run_process(dataset_shuffle,grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2186626949582462"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dataset_shuffle.drop(TARGET, axis=1), np.array(dataset_shuffle[TARGET])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=40)\n",
    "grid_lr.best_estimator_.fit(X_train,y_train)\n",
    "ypred = grid_lr.best_estimator_.predict(X_test)\n",
    "grid_lr.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ypred,y_test)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_test')\n",
    "#plt.savefig('pruebas_rf_1234_0.3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02663843, -0.19872212, -0.00439224, -0.14332571, -0.01708011,\n",
       "        0.12535873,  0.17609598, -0.06799979,  0.21400562,  0.01645395,\n",
       "        0.05700936, -0.20199634, -0.2002811 , -0.075551  ,  0.12481333,\n",
       "       -0.01946991, -0.09757535, -0.03492168,  0.12196905,  0.17010609])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
